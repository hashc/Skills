{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "teacher_forcing_ratio = 0.5\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "# def filterPair(p):\n",
    "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "#         len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "#         p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "#     encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "#     decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        #Los.append(loss)\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 144528 sentence pairs\n",
      "Trimmed to 136304 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "at 98833\n",
      "level 6\n",
      "['au15800 au53845 au100405 au214299 t6835 t7320', 'e3']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('at', 'level', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.12).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 0m 45s) (100 5%) 1.2445\n",
      "0m 4s (- 0m 42s) (200 10%) 1.0692\n",
      "0m 6s (- 0m 39s) (300 15%) 0.9700\n",
      "0m 9s (- 0m 37s) (400 20%) 0.8631\n",
      "0m 11s (- 0m 34s) (500 25%) 0.7868\n",
      "0m 13s (- 0m 32s) (600 30%) 0.7511\n",
      "0m 16s (- 0m 30s) (700 35%) 0.7049\n",
      "0m 18s (- 0m 27s) (800 40%) 0.7099\n",
      "0m 20s (- 0m 25s) (900 45%) 0.6697\n",
      "0m 23s (- 0m 23s) (1000 50%) 0.6796\n",
      "0m 25s (- 0m 20s) (1100 55%) 0.7351\n",
      "0m 27s (- 0m 18s) (1200 60%) 0.6707\n",
      "0m 30s (- 0m 16s) (1300 65%) 0.6434\n",
      "0m 32s (- 0m 13s) (1400 70%) 0.6566\n",
      "0m 34s (- 0m 11s) (1500 75%) 0.6735\n",
      "0m 37s (- 0m 9s) (1600 80%) 0.6577\n",
      "0m 39s (- 0m 6s) (1700 85%) 0.6483\n",
      "0m 41s (- 0m 4s) (1800 90%) 0.6433\n",
      "0m 44s (- 0m 2s) (1900 95%) 0.6208\n",
      "0m 46s (- 0m 0s) (2000 100%) 0.6559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8VOWhxvHfm52QhawkrCEBwg5CRJBdXBBbba9YtW51o2htaxdvbW9vF2/vUtuq7a07WrdqVaxVqVbEggiCmACyE0LCEpYkQEhCICHLe/+YgRtDQgYymTPL8/188slkzpmZh8PwcPLOOe8x1lpERCS4hDkdQEREvE/lLiIShFTuIiJBSOUuIhKEVO4iIkFI5S4iEoRU7iIiQUjlLiIShFTuIiJBKMKpF05NTbVZWVlOvbyISEAqKCg4aK1N62g9x8o9KyuL/Px8p15eRCQgGWN2ebKehmVERIKQyl1EJAip3EVEgpDKXUQkCKncRUSCkMpdRCQIqdxFRIJQwJV7YVkN/7FwM/WNTU5HERHxWwFX7qWVx3hmeQmrSw47HUVExG8FXLlPzE4lKiKMJVsrnI4iIuK3Aq7cu0WFMzE7haXbyp2OIiLitwKu3AFm5KZRfLCWXYdqnY4iIuKXArLcp+emA7B0m4ZmRETaEpDlnpXanQGp3VmioRkRkTYFZLkDTM9NY+WOQxw/oUMiRURaC9hyn5GbTn1jM6uKDzkdRUTE7wRsuY8fkEy3yHANzYiItCFgyz0mMpxJA1NYuq0Ca63TcURE/ErAljvAtNx0dh8+RvFBHRIpItJSh+VujHnWGFNujNnYzvIbjDHr3V+fGGNGez9m26YPdl0jdslWDc2IiLTkyZ77c8CsMywvAaZZa0cB/wE85YVcHumbHMug9Dgd7y4i0kqH5W6tXQa0O0uXtfYTa22l+8dVQB8vZfPIjCHpfFpyiNr6Rl++rIiIX/P2mPvtwHvtLTTGzDXG5Btj8isqvLO3PT03jYYmy4qig155PhGRYOC1cjfGzMBV7j9qbx1r7VPW2jxrbV5aWppXXjevfzJx0REsLdTQjIjISRHeeBJjzChgPnC5tdanZxVFRYS5DoncWo61FmOML19eRMQvdXrP3RjTD/grcJO1trDzkc7ejNx09lXVUVh21ImXFxHxOx3uuRtjXgGmA6nGmFLg50AkgLX2CeBnQArwmHuvudFam9dVgdtycpbIJdvKyc2I9+VLi4j4pQ7L3Vp7fQfL7wDu8Fqic5CRGMPQzASWbC1n3rQcJ6OIiPiFgD5DtaUZuWnk76qkuq7B6SgiIo4LnnIfkk5Ts2XFdh0SKSISNOV+Xt8eJMREaJZIERGCqNwjwsOYMjiNJZolUkQkeModXIdEVtTUs2lftdNRREQcFVTlPs09S+RSDc2ISIgLqnJPi49mVJ9EzRIpIiEvqModXHO8r9ldyZFjJ5yOIiLimOAr9yHpNFtYpkMiRSSEBV25j+7Tg6TYSJbq6kwiEsKCrtzDwwzTBqextLCC5mYdEikioSnoyh1cZ6serj3B+r1VTkcREXFEUJb71EFpGKNDIkUkdAVluSd1j2JM3x4s0SGRIhKigrLcwXW26vrSIxw8Wu90FBERnwvqcrcWlunaqiISgoK23If3SiA1LlpDMyISkoK23MPCDNNz01hWWEFjU7PTcUREfCpoyx1cQzNVxxv4vPSI01FERHwqqMt98qBUwsMMS7ZqaEZEQktQl3tit0jG9UvS1ZlEJOQEdbkDTB+SxqZ91ZRV1zkdRUTEZ4K+3GfkpgPwkY6aEZEQEvTlPiQjnoyEGA3NiEhICfpyN8Z1SOTy7Qdp0CGRIhIigr7cAabnplNT30jBrkqno4iI+ERIlPukgSlEhhsNzYhIyAiJco+PieT8rGSW6nh3EQkRIVHu4DpqZltZDfuOHHc6iohIlwudch+SBsBSHRIpIiEgZMo9Jy2O3j26adxdREJCyJS7MYYZQ9JYUXSQ+sYmp+OIiHSpkCl3cI27HzvRxGclOiRSRIJbSJX7xJwUoiLCNDQjIkEvpMo9NiqCCdkpKncRCXohVe4AM3LTKK6opai8xukoIiJdJuTK/UujetEtMpxHl+xwOoqISJcJuXJPi4/m5gv787d1e7X3LiJBK+TKHeCbU3OIjQznkcXbnY4iItIlQrLck7tHceukASxcv5+tB6qdjiMi4nUhWe4Ad0wZQHx0BI98oL13EQk+IVvuPWKjuH3KAP6x6QAb91Y5HUdExKtCttwBbps8gISYCB5ZXOh0FBERrwrpck+IiWTu1GwWbyln3Z4jTscREfGakC53gG9MGkBSbCQPf6C9dxEJHiFf7nHREXxzWg4fFVZQsOuw03FERLwi5Msd4OaJ/UmNi+Ih7b2LSJBQueOaUGzetBxWFB1iVfEhp+OIiHSayt3txgn9SY+P5qEPCrHWOh1HRKRTVO5uMZHhfGvGQFaXHGZFkfbeRSSwqdxbuG58XzITY3jog23aexeRgKZybyE6Ipx7LhrImt1HWFpY4XQcEZFzpnJv5ZpxfemT1I2HNfYuIgFM5d5KVEQY37loEOtLq1i8RZfjE5HA1GG5G2OeNcaUG2M2trPcGGP+YIwpMsasN8aM9X5M3/qXsb3pnxLLQx8U0tysvXcRCTye7Lk/B8w6w/LLgUHur7nA452P5ayI8DC+O3MQW/ZX8/6mA07HERE5ax2Wu7V2GXCm8/KvAl6wLquAHsaYTG8FdMpVY3qTndadhxdr711EAo83xtx7A3ta/Fzqvi+ghYcZ7r14MIVlR1m4Yb/TcUREzoo3yt20cV+bu7rGmLnGmHxjTH5Fhf8favilkZkM7hnHI4sLadLeu4gEEG+UeynQt8XPfYB9ba1orX3KWptnrc1LS0vzwkt3rbAww/cuHkxxRS1vrdvrdBwREY95o9zfBm52HzUzAaiy1gbNOMZlwzMYmpnA7z/cTmNTs9NxREQ84smhkK8AK4FcY0ypMeZ2Y8w8Y8w89yrvAsVAEfA0cHeXpXVAWJjh+5cMZtehY/x1jfbeRSQwRHS0grX2+g6WW+BbXkvkhy4ems6oPon84Z/b+cp5vYmK0LlfIuLf1FIeMMbwvUsGU1p5nNcL9nT8ABERh6ncPTR9cBrn9evBH/9ZRH1jk9NxRETOSOXuIWMMP7gkl/1VdfxltfbeRcS/qdzPwqSBKYzPSubRJUXUNWjvXUT8l8r9LJwcey+vqee1fO29i4j/UrmfpQnZyYzt14MnPyqmQce9i4ifUrmfJWMMd08fyN4jx3nn8zZPxBURcZzK/RxcNCSd3J7xPL50h2aMFBG/pHI/B2Fhhrum57C9/CiLt5Q5HUdE5DQq93P0pVGZ9E3uxmNLd+haqyLid1Tu5ygiPIy5U3NYt+cIK4sPOR1HROQLVO6dcM24PqTGRfP40h1ORxER+QKVeyfERIZz2+QsPt5+kA2lVU7HERE5ReXeSTdO6E98dASPf1TkdBQRkVNU7p2UEBPJTRP7897GA+yoOOp0HBERQOXuFbdNHkBUeBhPfqSxdxHxDyp3L0iNi+ba8/vy5tq97K867nQcERGVu7fcOSWbZgtPLytxOoqIiMrdW/omx3LV6F68sno3h2tPOB1HREKcyt2L5k3P4XhDE899stPpKCIS4lTuXjS4ZzyXDOvJ85/s5Gh9o9NxRCSEqdy97O7pOVQdb+CVT3c7HUVEQpjK3cvO65fExOwU5i8v1oW0RcQxKvcucPeMHMqq6/nrmr1ORxGREKVy7wKTB6YysnciT360gyZdzENEHKBy7wKuS/HlsPPQMd7dsN/pOCISglTuXeSy4Rlkp3XXxTxExBEq9y4SFmaYNy2HLfur+aiwwuk4IhJiVO5d6CtjepOZGMNjupiHiPiYyr0LRUWEceeUbFaXHKZg12Gn44hICFG5d7HrxvclKTaSx5Zo711EfEfl3sVioyK4ddIAPtxaztYD1U7HEZEQoXL3gZsn9qd7VLgupC0iPqNy94EesVF8/YJ+vPP5PnYfOuZ0HBEJASp3H7ljSjYRYWE8uUx77yLS9VTuPtIzIYarx/Xm9YJSymvqnI4jIkFO5e5D35yaQ2NTM88s16X4RKRrqdx9KCu1O7NHZvLnVbs5ckyX4hORrqNy97F7LhrI8YYmfvX3LU5HEZEgpnL3sSEZCdw1LYcFBaUs2VbudBwRCVIqdwd8e+ZABveM48dvbKC6rsHpOCIShFTuDoiOCOc3c0ZTXlPHfy7U8IyIeJ/K3SGj+/bgm9NyeDV/D8s0JbCIeJnK3UHfnTmIgelx3P/Gemo0PCMiXqRyd1BMZDgPzhnFgeo6/vu9rU7HEZEgonJ32Nh+SdwxJZuXP93N8u0HnY4jIkFC5e4Hvn/JYLJTu/OjN9ZztL7R6TgiEgRU7n4gJjKc31wzin1Vx/m1hmdExAtU7n5iXP9kbps0gBdX7eKTHRqeEZHOUbn7kR9emktWSiw/emM9tRqeEZFOULn7kW5R4Tw4ZzSllcf5zfvbnI4jIgFM5e5nxg9I5paJWTz3yU5WFR9yOo6IBCiVux/611m59Et2Dc8cP9HkdBwRCUAqdz8UGxXBg3NGsevQMQ3PiMg58ajcjTGzjDHbjDFFxpj721jezxizxBiz1hiz3hgz2/tRQ8uE7BRuntifP31SQv7Ow07HEZEA02G5G2PCgUeBy4FhwPXGmGGtVvsp8Jq19jzgOuAxbwcNRT+aNYTePbpx34L11DVoeEZEPOfJnvt4oMhaW2ytPQH8Bbiq1ToWSHDfTgT2eS9i6OoeHcGDV4+i5GAtv1uk4RkR8Zwn5d4b2NPi51L3fS39ArjRGFMKvAt82yvphAsHpnLDBf2Yv7yEgl2VTscRkQDhSbmbNu6zrX6+HnjOWtsHmA28aIw57bmNMXONMfnGmPyKCs1h7qkfzx5Kr8Ru3Lfgcw3PiIhHPCn3UqBvi5/7cPqwy+3AawDW2pVADJDa+omstU9Za/OstXlpaWnnljgExUVH8D9Xj6S4opaHFxc6HUdEAoAn5f4ZMMgYM8AYE4XrA9O3W62zG5gJYIwZiqvctWvuRVMGpXH9+L48vayYtbs1PCMiZ9ZhuVtrG4F7gPeBLbiOitlkjHnAGHOle7UfAHcaYz4HXgG+Ya1tPXQjnfST2UPJSIjhvgWaGlhEzsw41cF5eXk2Pz/fkdcOZMsKK/jGn1bTNzmWR64dw3n9kpyOJCI+ZIwpsNbmdbSezlANMFMHp/GXuRNpbLLMeWIlv1+8ncamZqdjiYifUbkHoPEDknnv3ilcOboXDy8u5GtPrmTXoVqnY4mIH1G5B6iEmEgevnYMf7j+PLaXH2X27z/m9fw96KMOEQGVe8C7cnQv/nHvVEb0TuS+Bev51strqKw94XQsEXGYyj0I9O7RjZfvnMCPZg3hg81lzPr9MpZv16X6REKZyj1IhIcZ7pqew5t3TyIuOoIbn/mUXy3crDNaRUKUyj3IjOidyMJvT+GmCf2Zv7yErzy6gm0HapyOJSI+pnIPQt2iwvmPr4zg2W/kcfBoPV/+43KeXV5Cc7M+bBUJFSr3IHbRkJ78496pTBmYygMLN3PLn1ZTVl3ndCwR8QGVe5BLjYtm/i15/OdXR/DZzsPMemQZ/9h4wOlYItLFVO4hwBjDDRf05+/fmUKfpFjmvVTAwx8U6ph4kSCmcg8hOWlxvHHXhVwzrg+//3A7P3trE00ahxcJShFOBxDfiooI48E5o0iOi+LJj4o5fOwED31tNNER4U5HExEvUrmHIGMMP758KCndo/ivd7dSdayBJ24aR1y03g4iwULDMiFs7tQcfnvNaFYWH+KGp1dx6Gi905ECgmbhlECgcg9xc8b14ckbx7H1QA3XPLmS0spjTkfya8sKKxjzwAe8uHKn01FEzkjlLlw8rCcv3XEBFTX1zHl8JYVlOqO1Lev2HGHeSwXUNTTxy3c289nOw05HEmmXyl0AOD8rmde+OZFma7nmiZUU7NJ1WlvaUXGUW/+0mpS4KP5x71T6JHXj7j+voVwnhYmfUrnLKUMzE3jjrgtJio3kxvmfsmRbudOR/MKBqjpufmY1Ycbwwm0XMDA9jiduGsfRukbueXktDRqDFz+kcpcv6Jscy4K7LiQ7rTt3Pp/P39budTqSo6qONXDLs6s5cuwEz906ngGp3QEYkpHA/1w9ktU7D/Nf725xOKXI6VTucprUuGj+MncC52clc++r63h2eYnTkRxR19DEHS98RsnBWp66OY+RfRK/sPyqMb25dVIWf1qxk7fWhfZ/guJ/VO7SpviYSP506/nMGp7BAws389v3t4XUdAWNTc3c8/Ia8ndV8vC1Y5g0MLXN9X4yeyjnZyVx/xsb2Hqg2scpRdqncpd2xUSG8+gNY7l+fF/+uKSIn7y5odPTFVhrOdHo32PU1lp+8uYGFm8p54Erh3PFqMx2140MD+PRr48lLiaCeS8WUHW8wYdJRdqnUxLljMLDDP/11ZGkdI/mj0uKqKxt4JHrxhAT+cXpCqy1VB1voKy6nvKaOsqr6ylzf6+oqaesuo7yGteyhibLvGnZfP+SXMLDjEN/svb95v1tvJZfyncuGshNE7M6XD89IYbHbxjLdU+t4gevreOpm/II88M/l4QWlbt0yBjDDy/LJbl7FA8s3MyN8z9lWK8Eyt1FXlZdT8XR+jb3yOOjI0hLiKZnfAzn9etBenw0B6rreXTJDjbureb3142hR2yUA3+qtj27vITHlu7g+vH9+N4lgz1+XF5WMj+9Yii/eGczjy4p4tszB3VhSpGOqdzFY7dNHkBy9yh+8uYGCstqSE+IoWdCNOMHJJMeH016Qgzp8dH0dH9PT4gmNqrtt9jE7BR+/vZGrvzjCp68aRxDMxN8/Kc53Vvr9vLAws3MGp7Br74yAmPObu/7lguzWLfnCA8tLmRU3x5MG5zWRUlFOmac+pAsLy/P5ufnO/La0jnW2rMuvrYU7Krk7j8XUH28kV/PGcWVo3t5Id25+aiwgtuf+4xx/ZN4/rbxpw07eer4iSa++tgKDlTX8c49k+mbHOvlpBLqjDEF1tq8jtbTB6py1rxR7ADj+ifxzrcnM6J3At95ZS2/WrjZkUm51u05wl0vFTCoZzxP35J3zsUOruvXPnHjOJqa7ampCkScoHIXR6XHx/DnOyZwy8T+zF9ewk3PrPbp7JQtpxV4/tbzSYiJ7PRzZqV255Frx7BpXzU//dvGkDqEVPyHyl0cFxURxi+vGsFvrxnNmt2VfPl/l7OhtKrLX/fktALhYYYXb7uA9IQYrz33zKE9+c7MQSwoKOXl1bu99rwinlK5i9+YM64PC+ZdiDGGq5/4hNfz93TZa7WeViDLPa2AN907cxDTc9P4xdubWLtbE7GJb6ncxa+M7JPI2/dMIq9/EvctWM+//22j1096qmto4vbn/39agRG9Ezt+0DkICzM8cu0YMhJjuOulNRzUxVDEh1Tu4ndS4qJ54bbxzJ2azYurdvH1p1d5ZWrdytoTLN9+kHkvFVCw+8zTCnhLj9goHr9hHJXHTnDPy2t0FSfxGR0KKX7tnc/38a8L1hMfE8HjN45jXP8kjx5XXl3Hxn1VbNxbzSb3971HjgMQZuCXV43gpgn9uzL6F7xRUMoPXv+cb07N5sezh/rsdSX4eHoopE5iEr/25dG9GNQzjrkvFHDdUyv5+ZeHc8MF/U4djmmtpbTy+KkCP1noLYdAslO7M7Z/EjdN7M+IXokM75VAUnffnhV79bg+rNtzhCeXFTO6bw9mj2x/vhp/Za2lsOwoHxWWMyA1jimDUjt12Kh0LZW7+L0hGQm8c89kvvvqWn76t40U7KokLT6ajXur2LSv+tRkXeFhhkHpcUwbnMaI3gkM75XI0Mx44r1weKM3/PuXhrFpXxX3vf453SLDmZ6b5rVzBrpSYVkNC9fv590N+ykqP3rq/m6R4UwdnMqlwzK4aEi6z//DlDPTsIwEjKZmyyOLC/nffxYRFR7GkMx4hvdKZETvBEb0SiQ3I97v9yQPVNVx/dOrKDlYy8TsFH48ewij+vRwOtZpWhe6MXDBgGSuGJnJzKE9Ka6oZdHmAyzaVMaB6jrCwwzjs5K5dHhPLhnWkz5JOjO3q3g6LKNyl4BTWXuCuJgIIsMD83iAE43NvLJ6N3/4cDuHak9wxahM7rs0t0sOxzwbhWU1/H39fv7eotDHZyXzpVGZXDYig/T4088DsNayYW8VizaVsWjzAQrLXHv2w3slcOmwDC4d3pMhGfEB8RtKoFC5i/i5mroGnv64hPkfF3OisZmvX9CP78wcRGpctM8ybG+xh769RaFfMSqTWcMzzvrErpKDtSzadIBFm8tYs7sSa6FfciyXDuvJpcMzGNc/yS+neQ4kKneRAFFeU8cfPtzOK6v3EBMRxp1Ts7lzSjbdo73/kdjJD0Xf27ifv6///0I/372Hfi6F3p7ymjo+3FLOok0HWFF0iBNNzSR3j2LmkHTOH5DMsMwEBvWMIzrCv4fSvK2mroFukeFEnONvnip3kQBTXHGU3y7axrsbDpAaF8V3Zw7iuvH9Oj38tO/IcVYUHeSTHYdYUXSQ8pr6U4V+xchMLh/hvUJvz9H6Rj7aVsGizQf459ZyauoaAYgIM+SkxTGsVwLDMhMYmpnAsF4JJAfph7OfFh/i+699ztfy+vLdi89tzn+Vu0iAWru7kv9+byurSw6TlRLLfZcNYfbIDI/HrStrT7Cy+NCpQi85WAtASvcoJuakcGFOKjOHptOziwu9Pc3Nll2Hj7F5XzWb91exZX8Nm/dVc6DFiWoZCTEMzYxnWC934WcmkJXSPWCvcFXf2MRDiwp56uNi+ifH8tC1Yxjbz7NzNlpTuYsEMGstS7aV8+v3trGtrIbRfRK5//KhTMxJOW3dYycaWV1y+NSe+eb91VgL3aPCuSA7hQtzUpg0MJXcnvF+XY6Ha0+wZX+1u/Sr2bK/mu3lR09dtzc2KpzcjHiGZibQNyn21AVh0uNdF4fpERvplx/cbtlfzfdeXcfWAzV8/YJ+/NvsoZ0aclO5iwSBpmbLX9eU8tAHheyvqmN6bho/uCSXusYm15550SHW7qmkockSFR7Gef16MGlgKpMGpjCqT4+APaLopLqGJorKj7LZXfpb3KVf7R7WaSkqPIy0+GjS4qNPK/6Wt1Pion3yoW5Ts2X+x8X8blEhCd0ieXDOSC4a0rPTz6tyFwkidQ1NPP/JTh5dUnSq2IyBkb0TmZiTwqScVM7PSqZbVGh8OFlb3+i64PqpC6+7rudbUf3/t8tr6jlyrOG0x4aHGaYNTuOOyQOYmJPSJXv7ew4f4wevf87qksNcNrwn//0vo7z2OYLKXSQIHTl2gjfX7iUzsRsTs1NIjPWPs2/9VV1DExXu8q9wF/7uQ8d4c+1eDtWeYGhmAndMHsCXR/ciKqLzv+VYa1lQUMov39kMwC+uHM7VY3t79T8QlbuISDvqGpp4a91e5n9cwvbyo6THR3PLhVl8fXy/c55G4dDRen7y5gbe31TG+AHJ/O6a0V1yDV2Vu4hIB6y1LNt+kPkfF/Px9oPERIYxZ1wfbps0gOy0OI+f559by/jXBRuoPt7ADy8bzO2Ts7tsXF+zQoqIdMAY1/j7tMFpbDtQwzPLi3nts1JeWrWbi4emc/vkbCZkJ7c7rFJb38iv/r6FV1bvZkhGPC/ePp6hmQk+/lO0TXvuIiItVNTU8+KqXby0aheHa08wvFcCd0wZwBUjvzguX7Crku+/to7dh48xd2o2379ksE/OttWwjIhIJ9Q1NPHm2r08s7yEovKj9ExwjctfM64vL6x0HbmUmdiNh742mguyTz//oKuo3EVEvKC52fLR9gqe+biE5UUHT90/Z1wffv7lYT6/XoDG3EVEvCAszDAjN50Zuels2V/Nm2v3ktc/iUuHZzgd7YxU7iIiHhrqntwsEAT2uckiItImj8rdGDPLGLPNGFNkjLm/nXW+ZozZbIzZZIx52bsxRUTkbHQ4LGOMCQceBS4BSoHPjDFvW2s3t1hnEPBjYJK1ttIYk95VgUVEpGOe7LmPB4qstcXW2hPAX4CrWq1zJ/CotbYSwFpb7t2YIiJyNjwp997AnhY/l7rva2kwMNgYs8IYs8oYM8tbAUVE5Ox5crRMW+fdtj44PgIYBEwH+gAfG2NGWGuPfOGJjJkLzAXo16/fWYcVERHPeLLnXgr0bfFzH2BfG+u8Za1tsNaWANtwlf0XWGufstbmWWvz0tLSzjWziIh0wJNy/wwYZIwZYIyJAq4D3m61zt+AGQDGmFRcwzTF3gwqIiKe63BYxlrbaIy5B3gfCAeetdZuMsY8AORba992L7vUGLMZaALus9YeOtPzFhQUHDTG7DrH3KnAwQ7Xco6/5wP/z6h8naN8nePP+fp7spJjc8t0hjEm35O5FZzi7/nA/zMqX+coX+f4ez5P6AxVEZEgpHIXEQlCgVruTzkdoAP+ng/8P6PydY7ydY6/5+tQQI65i4jImQXqnruIiJyBX5d7R7NRGmOijTGvupd/aozJ8mG2vsaYJcaYLe6ZML/bxjrTjTFVxph17q+f+Sqf+/V3GmM2uF/7tMteGZc/uLffemPMWB9my22xXdYZY6qNMfe2Wsfn288Y86wxptwYs7HFfcnGmA+MMdvd35Paeewt7nW2G2Nu8WG+3xhjtrr/Dt80xvRo57FnfD90Yb5fGGP2tvh7nN3OYzucfbaL8r3aIttOY8y6dh7b5dvPq6y1fvmF65j6HUA2EAV8Dgxrtc7dwBPu29cBr/owXyYw1n07HihsI990YKGD23AnkHqG5bOB93BNMTEB+NTBv+sDQH+ntx8wFRgLbGxx34PA/e7b9wO/buNxybhO3EsGkty3k3yU71Igwn37123l8+T90IX5fgH80IP3wBn/vXdVvlbLfwf8zKnt580vf95z92Q2yquA5923FwAzjTFtzYXjddba/dbaNe7bNcAWTp9Qzd9dBbxgXVYBPYwxmQ7kmAnssNae60ltXmOtXQYcbnV3y/fZ88BX2njoZcAH1trD1jU76geA1yfQayuftXaRtbbR/eMqXFOEOKJlsFiSAAAC/UlEQVSd7ecJT/69d9qZ8rm742vAK95+XSf4c7l7MhvlqXXcb+4qwHeXIXdzDwedB3zaxuKJxpjPjTHvGWOG+zSYa4K3RcaYAvekba15so194Tra/wfl5PY7qae1dj+4/lMH2rpegb9sy9tw/TbWlo7eD13pHvew0bPtDGv5w/abApRZa7e3s9zJ7XfW/LncPZmN0pN1upQxJg54A7jXWlvdavEaXEMNo4H/xTUHjy9NstaOBS4HvmWMmdpquT9svyjgSuD1NhY7vf3Ohj9sy38DGoE/t7NKR++HrvI4kAOMAfbjGvpozfHtB1zPmffandp+58Sfy93T2Sj7AhhjIoBEzu1XwnNijInEVex/ttb+tfVya221tfao+/a7QKRxTazmE9bafe7v5cCbuH71bcmTbdzVLgfWWGvLWi9wevu1UHZyuMr9va2L0Ti6Ld0f4H4JuMG6B4hb8+D90CWstWXW2iZrbTPwdDuv6/T2iwD+BXi1vXWc2n7nyp/L3ZPZKN8GTh6VMAf4Z3tvbG9zj889A2yx1j7UzjoZJz8DMMaMx7W9zzihmhfzdTfGxJ+8jetDt42tVnsbuNl91MwEoOrk8IMPtbu35OT2a6Xl++wW4K021jk5eV6Se9jhUvd9Xc64Lo7zI+BKa+2xdtbx5P3QVflafo7z1XZe15N/713pYmCrtba0rYVObr9z5vQnumf6wnU0RyGuT9H/zX3fA7jexAAxuH6dLwJWA9k+zDYZ16+N64F17q/ZwDxgnnude4BNuD75XwVc6MN82e7X/dyd4eT2a5nP4Lo+7g5gA5Dn47/fWFxlndjiPke3H67/aPYDDbj2Jm/H9TnOh8B29/dk97p5wPwWj73N/V4sAm71Yb4iXOPVJ9+HJ48g6wW8e6b3g4/yveh+f63HVdiZrfO5fz7t37sv8rnvf+7k+67Fuj7fft780hmqIiJByJ+HZURE5Byp3EVEgpDKXUQkCKncRUSCkMpdRCQIqdxFRIKQyl1EJAip3EVEgtD/AXIb2NMrMLUoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(encoder1, attn_decoder1, 2000, print_every=100,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 39.2\n"
     ]
    }
   ],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=1000,show=False):\n",
    "    pp=0\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        #print('>', pair[0])\n",
    "        #print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        #print('<', output_sentence)\n",
    "        if  output_sentence.split(' ')[0]==pair[1]:\n",
    "            pp+=1\n",
    "        if show:\n",
    "            print('>', pair[0])\n",
    "            print('=', pair[1]) \n",
    "            print('<', output_sentence)\n",
    "    print(\"acc\",pp/n*100)\n",
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> au3045 au92641 au123256 t7847 t7135 t4265\n",
      "= e3\n",
      "< e1 <EOS>\n",
      "> au10813 au160927 au201360 au228788 t6610 t6835 t7215\n",
      "= e2\n",
      "< e1 <EOS>\n",
      "> au127716 au182458 t2920 t4170 t1220\n",
      "= e0\n",
      "< e1 <EOS>\n",
      "> au13085 au148586 au181831 au219269 t8105 t4755 t6630 t7660\n",
      "= e1\n",
      "< e1 <EOS>\n",
      "> au19462 au85333 au224019 t6350\n",
      "= e3\n",
      "< e1 <EOS>\n",
      "> au176106 au185873 t7420 t7480\n",
      "= e1\n",
      "< e1 <EOS>\n",
      "> au56794 au147795 au158399 au189845 au229170 t6835 t7320\n",
      "= e1\n",
      "< e1 <EOS>\n",
      "> au5623 au94355 au129321 t1480 t1215 t1340\n",
      "= e3\n",
      "< e1 <EOS>\n",
      "> au137351 au174206 au182724 t6112 t6125\n",
      "= e1\n",
      "< e1 <EOS>\n",
      "> au69731 au111898 au164582 au170624 au172737 au230626 t6116 t6835\n",
      "= e2\n",
      "< e1 <EOS>\n",
      "acc 40.0\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1,show=True,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "#     n=len([''] + input_sentence.split(' ') + ['<EOS>'])\n",
    "#     cax = ax.matshow(attentions.numpy()[0][:n], cmap='bone')\n",
    "    n=len([''] + input_sentence.split(' ') + ['<EOS>'])-2\n",
    "    cax = ax.matshow(attentions.numpy()[:1][:,:n], cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + [output_words[0]])\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "# evaluateAndShowAttention(\"au69686 au81092 t7420 t7145 t7110\")\n",
    "\n",
    "# evaluateAndShowAttention(\"au69686 au32005 au182604 au211382 t7110 t0365 t7460 t0545\")\n",
    "\n",
    "# evaluateAndShowAttention(\"au69686 au211382 t7110 t7460 t0545\")\n",
    "\n",
    "#evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "#evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = au30736 au102734 au194639 t7128 t7870\n",
      "output = e1 <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"au30736 au102734 au194639 t7128 t7870\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = au194639 t7870\n",
      "output = e1 <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"au194639 t7870\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence=\"au13258 au32005 au182604 au211382 t0365 t7460 t0545\"\n",
    "output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "n=len([''] + input_sentence.split(' ') + ['<EOS>'])-1\n",
    "cax = ax.matshow(attentions.numpy()[:1][:,:n], cmap='bone')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                   ['<EOS>'], rotation=90)\n",
    "ax.set_yticklabels([''] + [output_words[0]])\n",
    "\n",
    "# Show label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
